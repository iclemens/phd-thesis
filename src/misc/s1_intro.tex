\chapter{General introduction}
\newpage

Life began about four billion years ago with the encapsulation of self-replicating RNA in a lipidic membrane \cite<e.g.>{orgel1968}. Simple as these probionts were, they did not have any means of locomotion and thus relied in full on the currents to deliver nutrients required to replicate. 

As organisms evolved, specialized sensory and motoric structures allowed them to increase their interaction with the world. In the beginning ciliae and flagellae coupled with simple biochemical sensors allowed organisms to follow biochemical gradients and thus actively gather nutrients. The signal transduction pathways linking sensoric signals to motor actions were quite simple.

With the advent of more complex sensory systems, the amount of information available to drive behaviour increased enormously. Simple neural networks evolved to process these sensory signals into more abstract decisions about movement. These networks then evolved into the nervous system, culminating into the cerebral cortex, which attempts to compress the vast amounts of incoming information using predictive circuitry.

The cortex builds elaborate maps of the environment, keeping track of probable locations to find e.g. food and predators. To use these maps, the brain needs to know both its location and orientation within the environment. In this thesis, we will investigate how the brain processes the available sensory signals in the perception of gravity as well as travelled distance.

The signals used for navigation, including gravity and distance perception, can be split in two broad categories: absolute signals and relative signals. Absolute signals, such as landmarks, can be used to directly estimate the location and orientation of an animal while relative signals, such as acceleration, are first integrated (i.e. dead reckoning or path integration) and then used to update previous estimates.

In the following section both absolute and relative sensory sources used for gravity and/or distance perception are considered in more detail.

\section{Sensory signals}
While many sensory organs supply information used in navigation, there is one system that evolved specifically for this purpose: the vestibular system (see \figref{intro:fig6}). Its two components, the semicircular canals and the otoliths, are housed in the labyrinth of the temporal bone in the inner ear and are sensitive to angular and linear acceleration respectively.

\subsection{Vestibular system}

\begin{figure}
    \includegraphics[width=0.5\textwidth]{src/misc/figures/Vestibular.png}
    \caption{Schematic view of the inner ear complex consisting of the auditory system (cochlea) and the vestibular system. The vestibular system has three angular velocity (semicircular canals) and two linear acceleration (saccule and utricle) sensors.}
    \label{intro:fig6}
\end{figure}


\subsubsection{Semicircular canals}
The semicircular canals measure rotational acceleration of the head. Each of the six  canals consists of a circular tube filled with a fluid known as endolymph (see \figref{intro:fig3}A). One part of the tube, the ampulla, is a bit thicker than the rest and contains a membrane, the cupula, that separates the fluid. When the head rotates, the fluid stays behind because of its inertia which in turn causes the membrane to deflect (see \figref{intro:fig3}B). Special hair cells, partly embedded in the cupula, measure this deflection and thus rotational acceleration. 

Each side of the head contains three orthogonally oriented semicircular canals, allowing rotation to be perceived in all three dimensions. Because they are only sensitive to rotation, that is change in orientation, they do not directly report on the static orientation of the head within the world. In addition, the canals are not sensitive to linear acceleration because of their circular nature.

\begin{figure}
    \includegraphics[width=1.0\textwidth]{src/misc/figures/Canals.png}
    \caption{Detailed view of a semicircular canal \panelref{A} in rest and \panelref{B} during rotation. Inertia of the endolymph in the canal causes the cupula to deflect during rotation.}
    \label{intro:fig3}
\end{figure}


\subsubsection{Otoliths}
Linear acceleration is instead measured by the otolith organs. Each otolith consists of endolymph filled compartments filled with otoconia, calcium carbonate crystals which, due to their high inertia, fall behind when the body is accelerating and move ahead during deceleration. The otoconia are mounted on top of a polysaccaride gel in which the cilia of hair cells are bathed. These cells detect the movement of their hairs, and therefore the gel and otoconia, and are thus sensitive to linear acceleration.

Because gravity also affects the otoconia, the vertically oriented ones are always deflected downward. It is therefore impossible to differentiate the linear acceleration from gravity based on the otolith signal alone. While various theories have been proposed to differentiate these stimuli, recent research favours the canal-otolith interaction theory as first proposed by Merfield and Zupan \textbf{(check the year)}. In short, they state that the relative canal signal is used to update the direction of gravity and that this estimate of gravity is then subtracted from the otolith signal in order to obtain an estimate for linear accleration.

While the semicircular canals were able to sense rotation in three dimensions due to their orthogonal organization, there are only two otoliths on each side of the head. Because the surfaces of both otoliths, the horizontally oriented utricle and the vertically oriented saccule are curved, the orientation of the haircells determines direction sensitivity. 

\begin{figure}
    \includegraphics[width=1.0\textwidth]{src/misc/figures/Otoliths.png}
    \caption{Detailed view of an otolith \panelref{A} in rest, \panelref{B} during head tilt, and \panelref{C} during linear acceleration. The high inertia of the otoconia keeps them from moving rapidly during both head tilt as well as linear acceleration. As the effect is physically identical in either case, head tilt and linear acceleration cannot be disambiguated based on the otolith signal alone.}
    \label{intro:fig7}
\end{figure}


\subsection{Somatosensory}
The gravito-intertial force caused by gravity or acceleration influences not only the vestibular system, but all other organs as well and can thus be used for both perception and action. The first evidence that these effects were used by the brain came from DeKleyn and Versteegh \citeyear{dekleyn1933} who showed that intertial reflexes still occurred after removal of the otolith organs.

Since then, the contribution of specific organs to GIF perception has been demonstrated. When the stomach is full, for example, performance on the subjective visual vertical (SVV) task, that is orienting a visual line with gravity, improves compared to when it's empty. This suggests that signals from the stomach are used in the perception of vertical \cite{trousselard2004}. Furtermore, SVV performance was shown to decrease when a body-cast was applied. As the cast attentuates skin pressure, this result suggests that skin pressure is also an important cue \cite{trousselard2004}. Similar results were obtained for many other organs, such as the blood vessels \cite{vaitl2002}, kidneys and spinal axis fluid \cite{vaitl1997}.

While these studies have only shown that these signals are used in the perception of gravity, it is not possible for these organs to distinguish between gravity and linear acceleration. As the signal is therefore a combination of both, it is only logical to assume that they also play a role in the perception of linear acceleration.

\subsection{Visual}
Even though the vestibular and somatosensory systems directly measure the gravito-intertial force, orientation and navigational information can also be extracted from the visual system. In many cases, especially when the low latency of the vestibular signal is not required, the visual signal even overshadows the vestibular one (reference).

\subsubsection{Vection}
When we move through the environment, the image of the world on our retina shifts. This large-field shift pattern, also known as optic flow, depends on the movement being made. Lateral translation (\figref{intro:fig2}A) for example causes a different pattern from roll rotation (\figref{intro:fig2}B). At the turn of the 19th century von Helmholz \citeyear{vonhelmholz1910} recognized the importance of these flow signals for self-motion perception. In some cases the vection signal is so strong, it causes a percept of self-motion in stationary participants. This happens, for example, when sitting in a train and the neighboring train starts to move. This effect is much less likely to occur when e.g. on the platform, suggesting that the vection signal is integrated with prior knowledge about the environment before causing self-motion perception (reference).

Similar retinal shifts are also observed during movement of the eyes or head as well as motion of the environment. When interpreting optic flow the brain needs to distinguish object- from self-motion. 

% MORE ABOUT DISTINGUISHING OBJECT FROM SELF-MOTION


\begin{figure}
    %\includegraphics[width=1.0\textwidth]{src/misc/figures/Vection.pdf}
    
    \caption{Vection pattern during \panelref{A} lateral translation and \panelref{B} rotation.}
    \label{intro:fig2}
\end{figure}

\subsubsection{Landmarks}
In addition to relative cues, the brain also uses absolute cues in both the perception of gravity as well as our location, and thus displacement. For the perception of gravity, it makes use of the fact that many lines within the world are aligned with either the horizon or gravity. Straight lines therefore acts as a priors attracting the perceived direction of gravity torwards them. A special case is the rod-and-frame illusion (\figref{intro:fig9}), where the perceived angle of a rod relative to gravity is affected by the orientation of the frame that contains it (reference). 

\begin{figure}
	%\includegraphics[width=1.0\textwidth]{src/misc/figures/RodFrame.pdf}
	\caption{..}
	\label{intro:fig9}
\end{figure}

Similarly, our absolute position within the world can be established using world-fixed landmarks. With the exception of animals and vehicles, most items in the world rarely change position. By comparing our current visual scene (e.g. \figref{intro:fig1}) with our knowledge of the enviroment we can determine our location (in this case Grand Canyon). Because the experiments outlined in this thesis were performed in near darkness, these absolute  navigational cues are less relevant. 

% Why not use redwood forest instead? It has lots of vertical trees.
\begin{figure}
    \includegraphics[width=1.0\textwidth]{src/misc/figures/Canyon.pdf}
    
    \caption{While the scene in the left panel might not give precise information about your location in the world, it does narrow it down to somewhere in the vicinity of the Grand Canyon (right panel). In addition, the horizon in the scene gives information about the orientation of the horizontal plane and thus about the orientation of the viewer with respect to gravity. \copyright Mojan Brenn}
    \label{intro:fig1}
\end{figure}


\subsubsection{Oculomotor}
While retinal information plays an important role in orientation and navigation, other, extra-retinal, visual signals are also informative. Eye movements, for example, are known to increase postural sway in darkness \cite{glasauer2005}. The increased sway is likely compensation for perceived self-motion caused by these eye movements. Such percept could be a remnant of optic flow processing, even though there is no optic flow in darkness, the eye movement signal still reaches the neural network responsible for compensating optic flow for eye movements and as such leak into self-motion perception. Evidence for this can be found in the fact that postural sway decreases when a stable background is presented \cite{glasauer2005,rodrigues2015}, where the  flow during eye movements balances the eye movement signal itself.


\section{Reflexive uses for the self-motion}
While vection is an ideal cue in self-motion perception, it can cause the image on the fovea to blur which hampers visual perception. Several reflexive mechanisms attempt to keep fixation on target during self-motion. Two examples are the vestibulo-ocular reflex, the VOR, where the low-latency vestibular signal drives the reflex and the optokinetic reflex, the OKR, where optic flow acts as the source signal.

The optokinetic reflex [Expand on this]

As these VOR compensate for both rotation as well as translation, the VOR consists of two reflex arcs. The translational VOR, or TVOR, is driven by the otolith signal while the rotational VOR, or RVOR, is mainly driven by the semicircular canals. Unlike the visual system, the vestibular system does not require elaborate processing in order to drive the reflexive eye movements. Because of this, the reflex arc reaches the oculomotor system in just three neural links. This greatly reduces the latency of the VOR compared to that of the OKR and causes the VOR to dominate at higher frequencies \cite{schweigard1997}.

In both the OKR and the VOR the eye movements made consist of two parts, the smooth pursuit movement in which the eyes are kept on target using slow eye movements and the saccade in which the eyes are quickly moved back to their initial position. The fast movements are elicited when the eyes are about to lose track of the target because of physical constraints within the oculomotor system.

%Mergner and Rosemeier, 1998


\section{Integration of signals for action and perception}
While reflexes depend on minimally processed sensory signals by definition, higher animal functions can rely on more elaborate processing. One such step is multi-sensory integration, combining multiple sensory signals into one abstract percept. Before such integration can occur, the brain first establishes that the available cues are in accordance with each other. If that is the case, fusion of the cues occurs, if not only one signal dominates self-motion perception while the other cues are either ignored or interpreted as object motion.

In conflicting situations where visual cues contradict vestibular and proprioceptive ones a dominance of vision is observed \cite{berthoz1975}.

In contrast, linear acceleration can change the perceived velocity of a moving visual scene, indicaing dominance of the vestibular over the visual signal \cite{pavard1977}. Mainly at low image velocities! At high image velocities the visual signal still dominates.

As we have seen, multiple sensory systems provide information about both position and orientation at the same time. While the brain could take estimates from the most reliable system and ignore the rest, this is not what commonly happens.
Instead, the brain tends to integrate all available evidence in what is called statistically optimal integration. In some cases prior knowledge, for example the fact that we stand mostly upright, is also taken into account. When this is the case, we talk about bayesian integration.


\section{Reference frames and spatial updating}
The output of a sensory system is relative to a specific frame of reference. For example, retinal information initially enters the brain in a gaze-fixed frame of reference while information from the vestibular enters in a head-fixed reference frame. When information from different sensory sources is combined, the brain needs to convert the information into a common frame of reference using what is called a reference frame transformation.

These reference frame transformations are not static, but depend on the position of our body. For example when converting the gaze-fixed retinal signal into a head-centered frame of reference, the position of the eyes have to be taken into account. When the position of our body changes, e.g. when we move our eyes, all coordinates remembered within the moving frame of reference also need to be updated. For example, when moving the eyes remembered retinal information needs to be shifted in the opposite direction to remain at the correct relative position. This process is known as spatial updating or spatial constancy.

\section{Studying sensory signals}
A large part of  our knowledge on these and other aspects of sensory processing comes from psychophysical experiments. In this type of experiments the relation between physical stimuli, e.g. rotation angle, and perception, e.g. perceived body orientation, is quantified.

The two-alternative forced choice, or 2AFC, paradigm is commonly used in psychophyiscal experiments. Participants are presented with two stimuli, e.g. two translation distances, and are then forced to make a choice, e.g. on which of the translations was longer. By structurally manipulating one of the choices the point of subjective equality, or PSE, can be determined, that is the point at which the participant is unsure, i.e. picks a response at random, and perceives the stimuli as being equal. The difference between the PSE and the actual stimulus is known as the bias, represented by the Greek letter mu ($\mu$).

In addition to establishing perceptual equality, the uncertainty on the responses can also be determined by looking at the response-distribution as a function of the manipulated variable. This uncertainty is commonly quantified by the standard deviation, represented by the Greek letter sigma ($\sigma$).

The next four sections will explain the four 2AFC tasks used in the present work in more detail.

\subsection{Subjective body tilt}
In the subjective body tilt, or SBT, task the perceived body orientation with respect to a given body tilt angle is probed. Participants are first given a reference ange, e.g. 45 \si{\degree}, and are then rotated to an angle close to the reference angle, e.g. 46 \si{\degree} (see \figref{intro:fig4}A). They then have to indicate whether their current orientation is clockwise or counterclockwise with respect to the reference angle. By systematically probing rotation angles around the reference angle we can obtain both the bias and uncertainty on the percept of body tilt.

Most participants are able to do this perfectly, regardless of the reference angle (see \figref{intro:fig4}B). Their uncertainty does increase as a function of reference angle though (see \figref{intro:fig4}C).
As the SBT probes body orientation, the somatosensory signal originating from the torso can be used without any reference transformation and thus provides a direct contriubtion. Other sensory signals such as the vestibular signal can also be used, but only after a reference frame transformation.

\begin{figure}
    \includegraphics[width=1.0\textwidth]{src/misc/figures/SBT.png}
    
    \caption{}
    \label{intro:fig4}
\end{figure}


\subsection{Subjective visual vertical}
The subjective visual vertical, or SVV, task is a similar task in which participants have to judge the orientation of a line with respect to gravity. The PSE, that is the angle at which the line is perceived to be aligned with gravity, can be found by presenting lines at different angles and asking the participant whether the line is rotated clockwise or counterclockwise relative to gravity (see \figref{intro:fig5}A).

When seated straight this task, participants do not make any static errors and are very certain about their responses (see \figref{intro:fig5}B and C). This changes when first rotating the participant before the task. In general, the static error increases with tilt angle, the direction of the error is in the direction of the body midline, this effect is known as the Aubert or A-effect. At smaller angles overcompensation occurs and the static error moves in the oposite direction, that is away from the body midline. This latter effect is known as the E-effect and could be due to the effects of ocular counterroll (OCR).

\begin{figure}
    \includegraphics[width=1.0\textwidth]{src/misc/figures/SVV.png}
    
    \caption{}
    \label{intro:fig5}
\end{figure}

% 1.5.3  PSE in lateral translation
% 1.5.4  Spatial updating

\section{Outline of this thesis}
In this thesis we take a closer look at the way vestibular and visual signals are used in orientation and navigation. We start in Chapter 2 where we compute statistical properties of somatosensory and vestibular signals based on reverse engineering and the differential optimal integration of these signals in the SVV and SBT tasks. Next, we move from a statically activated otolith system to one that is activated by linear acceleration in Chapter 3. We show that eye movements, in the absence of visual input, are combined with this acceleration signal to provide an estimate of self-motion. Chapter 4 tentatively shows that the depth is only partially taken into account when processing this oculomotor signal. In Chapter 5 we show that gaze centered effects are present in spatial updating, and that underestimation of self-motion is a possible cause of these effects.

In summary ...
